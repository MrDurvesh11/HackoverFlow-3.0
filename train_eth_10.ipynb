{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cryptocurrency Price Prediction with LSTM - Multi-Step Forecasting\n",
    "\n",
    "This notebook trains an LSTM model to predict the next 10 cryptocurrency price candles using the processed data with technical indicators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Load the processed data\n",
    "# Replace with your actual file path\n",
    "processed_data_file = \"processed_eth1.csv\"\n",
    "df = pd.read_csv(processed_data_file)\n",
    "\n",
    "# Convert 'Open Time' to datetime\n",
    "df['Open Time'] = pd.to_datetime(df['Open Time'])\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Data shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill any remaining missing values\n",
    "df = df.ffill().bfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Feature Selection and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Select features for model training (exclude 'Open Time' as it's not a numeric feature)\n",
    "feature_columns = ['Close', 'Volume', 'Taker Buy Base Asset Volume', 'Taker Buy Quote Asset Volume',\n",
    "                    'rsi', 'macd', 'macd_signal', 'upper_band', 'lower_band']\n",
    "df_features = df[feature_columns]\n",
    "\n",
    "# Scale the features to be between 0 and 1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_features = scaler.fit_transform(df_features)\n",
    "\n",
    "# Create a separate scaler for the target variable ('Close') for later inverse scaling\n",
    "close_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "close_scaler.fit(df[['Close']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Create Time Series Dataset for Multi-Step Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length, forecast_horizon=10):\n",
    "    \"\"\"\n",
    "    Create sequences of data for multi-step time series prediction\n",
    "    \n",
    "    Args:\n",
    "        data: Scaled feature data\n",
    "        seq_length: Number of time steps to look back\n",
    "        forecast_horizon: Number of future time steps to predict\n",
    "        \n",
    "    Returns:\n",
    "        X: Input sequences (features)\n",
    "        y: Target values (next n closing prices)\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length - forecast_horizon + 1):\n",
    "        # Feature sequences (all features)\n",
    "        X.append(data[i:i+seq_length])\n",
    "        # Targets are the next 'forecast_horizon' closing prices\n",
    "        # We only take the first column (Close price) for targets\n",
    "        y.append(data[i+seq_length:i+seq_length+forecast_horizon, 0])\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Define sequence length (lookback period) and forecast horizon\n",
    "sequence_length = 60  # Look back 60 time steps\n",
    "forecast_horizon = 10  # Predict next 10 candles\n",
    "\n",
    "# Create sequences\n",
    "X, y = create_sequences(scaled_features, sequence_length, forecast_horizon)\n",
    "\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build LSTM Model for Multi-Step Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(input_shape, output_size):\n",
    "    \"\"\"\n",
    "    Build an LSTM model for multi-step time series prediction\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Shape of input data (sequence_length, num_features)\n",
    "        output_size: Number of future time steps to predict\n",
    "        \n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First LSTM layer with return sequences for stacking\n",
    "    model.add(LSTM(units=64, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Second LSTM layer\n",
    "    model.add(LSTM(units=64, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Third LSTM layer\n",
    "    model.add(LSTM(units=64))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Output layer with forecast_horizon units to predict multiple steps\n",
    "    model.add(Dense(units=output_size))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Get input shape from training data\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "output_size = forecast_horizon  # Number of future values to predict\n",
    "\n",
    "# Build the model\n",
    "model = build_lstm_model(input_shape, output_size)\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_lstm_model_multi_step.keras', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=140,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, model_checkpoint],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss During Training')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "predicted_scaled = model.predict(X_test)\n",
    "\n",
    "# Initialize arrays to store inverse-transformed values\n",
    "predicted_prices = np.zeros((predicted_scaled.shape[0], predicted_scaled.shape[1]))\n",
    "actual_prices = np.zeros((y_test.shape[0], y_test.shape[1]))\n",
    "\n",
    "# Inverse transform each step in the forecast horizon\n",
    "for i in range(forecast_horizon):\n",
    "    # Extract the i-th step predictions and actual values\n",
    "    pred_step = predicted_scaled[:, i].reshape(-1, 1)\n",
    "    actual_step = y_test[:, i].reshape(-1, 1)\n",
    "    \n",
    "    # Inverse transform to original scale\n",
    "    predicted_prices[:, i] = close_scaler.inverse_transform(pred_step).flatten()\n",
    "    actual_prices[:, i] = close_scaler.inverse_transform(actual_step).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Calculate performance metrics for each forecast step\n",
    "for step in range(forecast_horizon):\n",
    "    mse = mean_squared_error(actual_prices[:, step], predicted_prices[:, step])\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(actual_prices[:, step], predicted_prices[:, step])\n",
    "    r2 = r2_score(actual_prices[:, step], predicted_prices[:, step])\n",
    "    \n",
    "    print(f\"Step {step+1} (t+{step+1})\")\n",
    "    print(f\"  MSE: {mse:.2f}\")\n",
    "    print(f\"  RMSE: {rmse:.2f}\")\n",
    "    print(f\"  MAE: {mae:.2f}\")\n",
    "    print(f\"  R²: {r2:.4f}\")\n",
    "    print(\"---\")\n",
    "\n",
    "# Calculate overall metrics across all steps\n",
    "overall_mse = mean_squared_error(actual_prices.flatten(), predicted_prices.flatten())\n",
    "overall_rmse = np.sqrt(overall_mse)\n",
    "overall_mae = mean_absolute_error(actual_prices.flatten(), predicted_prices.flatten())\n",
    "overall_r2 = r2_score(actual_prices.flatten(), predicted_prices.flatten())\n",
    "\n",
    "print(\"Overall Performance:\")\n",
    "print(f\"  MSE: {overall_mse:.2f}\")\n",
    "print(f\"  RMSE: {overall_rmse:.2f}\")\n",
    "print(f\"  MAE: {overall_mae:.2f}\")\n",
    "print(f\"  R²: {overall_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Visualize Multi-Step Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Select a sample from the test set to visualize\n",
    "sample_idx = 10  # You can change this to visualize different samples\n",
    "\n",
    "# Create a time index for the selected sample\n",
    "test_start_idx = train_size + sequence_length\n",
    "sample_dates = df['Open Time'][test_start_idx + sample_idx:test_start_idx + sample_idx + forecast_horizon]\n",
    "\n",
    "# Get the actual and predicted values for this sample\n",
    "sample_actual = actual_prices[sample_idx]\n",
    "sample_predicted = predicted_prices[sample_idx]\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "results_df = pd.DataFrame({\n",
    "    'Date': sample_dates,\n",
    "    'Actual': sample_actual,\n",
    "    'Predicted': sample_predicted\n",
    "})\n",
    "\n",
    "# Plot actual vs predicted prices for this sample\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(results_df['Date'], results_df['Actual'], 'o-', label='Actual Price', color='blue')\n",
    "plt.plot(results_df['Date'], results_df['Predicted'], 'o--', label='Predicted Price', color='red')\n",
    "plt.title(f'Multi-Step Price Prediction - Sample {sample_idx}')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Visualize multiple samples\n",
    "num_samples = 5  # Number of samples to visualize\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    sample_idx = i * 20  # Space out the samples\n",
    "    if sample_idx >= len(actual_prices):\n",
    "        break\n",
    "        \n",
    "    # Get dates for this sample\n",
    "    sample_dates = df['Open Time'][test_start_idx + sample_idx:test_start_idx + sample_idx + forecast_horizon]\n",
    "    \n",
    "    # Get actual and predicted values\n",
    "    sample_actual = actual_prices[sample_idx]\n",
    "    sample_predicted = predicted_prices[sample_idx]\n",
    "    \n",
    "    # Plot\n",
    "    plt.subplot(num_samples, 1, i+1)\n",
    "    plt.plot(sample_dates, sample_actual, 'o-', label='Actual', color='blue')\n",
    "    plt.plot(sample_dates, sample_predicted, 'o--', label='Predicted', color='red')\n",
    "    plt.title(f'Sample {i+1}')\n",
    "    plt.ylabel('Price')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Future Price Prediction (Next 10 Candles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_prices(model, data, sequence_length, forecast_horizon, feature_scaler, close_scaler):\n",
    "    \"\"\"\n",
    "    Predict the next n closing prices\n",
    "    \n",
    "    Args:\n",
    "        model: Trained LSTM model\n",
    "        data: Full dataset\n",
    "        sequence_length: Number of time steps to look back\n",
    "        forecast_horizon: Number of future steps to predict\n",
    "        feature_scaler: Scaler used for features\n",
    "        close_scaler: Scaler used for the target variable\n",
    "        \n",
    "    Returns:\n",
    "        next_prices: Predicted next closing prices\n",
    "    \"\"\"\n",
    "    # Get the most recent sequence of data\n",
    "    last_sequence = data[-sequence_length:]\n",
    "    \n",
    "    # Scale the sequence\n",
    "    last_sequence_scaled = feature_scaler.transform(last_sequence)\n",
    "    \n",
    "    # Reshape for LSTM input [samples, time steps, features]\n",
    "    X_new = np.array([last_sequence_scaled])\n",
    "    \n",
    "    # Make prediction\n",
    "    predicted_scaled = model.predict(X_new)\n",
    "    \n",
    "    # Inverse transform to get the actual prices\n",
    "    predicted_prices = np.zeros(forecast_horizon)\n",
    "    \n",
    "    for i in range(forecast_horizon):\n",
    "        step_prediction = predicted_scaled[0, i].reshape(-1, 1)\n",
    "        predicted_prices[i] = close_scaler.inverse_transform(step_prediction)[0, 0]\n",
    "    \n",
    "    return predicted_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Predict the next 10 closing prices\n",
    "next_prices = predict_next_prices(model, df_features, sequence_length, forecast_horizon, scaler, close_scaler)\n",
    "\n",
    "# Get the last known price for comparison\n",
    "last_known_price = df['Close'].iloc[-1]\n",
    "\n",
    "print(f\"Last known closing price: ${last_known_price:.2f}\")\n",
    "print(\"\\nPredicted prices for next 10 candles:\")\n",
    "for i, price in enumerate(next_prices):\n",
    "    change = price - last_known_price\n",
    "    percent_change = (price / last_known_price - 1) * 100\n",
    "    print(f\"Candle {i+1}: ${price:.2f} (Change: ${change:.2f}, {percent_change:.2f}%)\")\n",
    "\n",
    "# Plot the predictions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(next_prices, 'o--', label='Predicted Prices', color='red')\n",
    "plt.title('Predicted Prices for Next 10 Candles')\n",
    "plt.xlabel('Candle')\n",
    "plt.ylabel('Price')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('ETH_lstm_model_multi_step.h5')\n",
    "\n",
    "# Save the scalers\n",
    "import joblib\n",
    "joblib.dump(scaler, 'ETH_feature_scaler_multi_step.save')\n",
    "joblib.dump(close_scaler, 'ETH_close_scaler_multi_step.save')\n",
    "\n",
    "print(\"Model and scalers saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "1. Loaded cryptocurrency data with technical indicators\n",
    "2. Modified the time series sequences for multi-step (10 candles) forecasting\n",
    "3. Built and trained an LSTM model that predicts the next 10 candles\n",
    "4. Evaluated the model's performance at each step of the forecast\n",
    "5. Visualized multi-step predictions\n",
    "6. Made a prediction for the next 10 candles\n",
    "\n",
    "The model can be further improved by:\n",
    "- Hyperparameter tuning (especially important for multi-step forecasting)\n",
    "- Experimenting with teacher forcing or other sequence-to-sequence architectures\n",
    "- Adding attention mechanisms to improve long-range predictions\n",
    "- Training separate models for different forecast horizons and combining them"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
